{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   magnitude  cdi  mmi  tsunami  sig  nst    depth  population\n",
      "0        6.5    7    4        0  657  114  192.955    100400.0\n",
      "1        6.5    8    6        0  775   92   69.727  10407607.0\n",
      "2        6.6    7    5        0  899   70  171.371    907006.0\n",
      "3        7.2    6    6        1  860  173   32.571      2591.0\n",
      "4        7.3    0    5        1  820   79   21.000      2600.0\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"augmented_dataset.csv\")\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dataset.drop(columns=\"sig\")\n",
    "target = dataset.sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_features, testing_features, training_target, testing_target = train_test_split(features, target, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(training_features)\n",
    "\n",
    "scaled_training_features = scaler.transform(training_features)\n",
    "scaled_testing_features = scaler.transform(testing_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "SANN_model = Sequential([\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "SANN_model.compile(\n",
    "    loss = \"mean_absolute_error\",\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.00025),\n",
    "    metrics = [\"mae\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 849.1400 - mae: 849.1400 - val_loss: 917126.0000 - val_mae: 917126.0000\n",
      "Epoch 2/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 842.2610 - mae: 842.2610 - val_loss: 2771853.7500 - val_mae: 2771853.7500\n",
      "Epoch 3/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 843.6917 - mae: 843.6917 - val_loss: 5619492.0000 - val_mae: 5619492.0000\n",
      "Epoch 4/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 838.1539 - mae: 838.1539 - val_loss: 10042764.0000 - val_mae: 10042764.0000\n",
      "Epoch 5/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 836.5748 - mae: 836.5748 - val_loss: 16434269.0000 - val_mae: 16434269.0000\n",
      "Epoch 6/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 833.9929 - mae: 833.9929 - val_loss: 25155604.0000 - val_mae: 25155604.0000\n",
      "Epoch 7/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 810.5310 - mae: 810.5310 - val_loss: 36154720.0000 - val_mae: 36154720.0000\n",
      "Epoch 8/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 807.1830 - mae: 807.1830 - val_loss: 49901748.0000 - val_mae: 49901748.0000\n",
      "Epoch 9/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 774.8778 - mae: 774.8778 - val_loss: 65572016.0000 - val_mae: 65572016.0000\n",
      "Epoch 10/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 778.2906 - mae: 778.2906 - val_loss: 84320456.0000 - val_mae: 84320456.0000\n",
      "Epoch 11/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 738.1887 - mae: 738.1887 - val_loss: 105380464.0000 - val_mae: 105380464.0000\n",
      "Epoch 12/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 702.9575 - mae: 702.9575 - val_loss: 129168360.0000 - val_mae: 129168360.0000\n",
      "Epoch 13/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 675.2600 - mae: 675.2600 - val_loss: 155197984.0000 - val_mae: 155197984.0000\n",
      "Epoch 14/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 602.7797 - mae: 602.7797 - val_loss: 185126320.0000 - val_mae: 185126320.0000\n",
      "Epoch 15/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 568.2567 - mae: 568.2567 - val_loss: 217117744.0000 - val_mae: 217117744.0000\n",
      "Epoch 16/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 509.2216 - mae: 509.2216 - val_loss: 252656000.0000 - val_mae: 252656000.0000\n",
      "Epoch 17/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 430.7391 - mae: 430.7391 - val_loss: 288222752.0000 - val_mae: 288222752.0000\n",
      "Epoch 18/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 362.2273 - mae: 362.2273 - val_loss: 320684128.0000 - val_mae: 320684128.0000\n",
      "Epoch 19/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 316.9615 - mae: 316.9615 - val_loss: 349681984.0000 - val_mae: 349681984.0000\n",
      "Epoch 20/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 291.5914 - mae: 291.5914 - val_loss: 374549600.0000 - val_mae: 374549600.0000\n",
      "Epoch 21/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 245.4939 - mae: 245.4939 - val_loss: 393380736.0000 - val_mae: 393380736.0000\n",
      "Epoch 22/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 226.7774 - mae: 226.7774 - val_loss: 409721216.0000 - val_mae: 409721216.0000\n",
      "Epoch 23/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 194.9088 - mae: 194.9088 - val_loss: 419998016.0000 - val_mae: 419998016.0000\n",
      "Epoch 24/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 177.4442 - mae: 177.4442 - val_loss: 426933504.0000 - val_mae: 426933504.0000\n",
      "Epoch 25/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 181.5664 - mae: 181.5664 - val_loss: 432783808.0000 - val_mae: 432783808.0000\n",
      "Epoch 26/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 159.7707 - mae: 159.7707 - val_loss: 435363968.0000 - val_mae: 435363968.0000\n",
      "Epoch 27/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 161.7966 - mae: 161.7966 - val_loss: 436186528.0000 - val_mae: 436186528.0000\n",
      "Epoch 28/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 142.9584 - mae: 142.9584 - val_loss: 437997856.0000 - val_mae: 437997856.0000\n",
      "Epoch 29/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 140.2876 - mae: 140.2876 - val_loss: 438344416.0000 - val_mae: 438344416.0000\n",
      "Epoch 30/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 144.5690 - mae: 144.5690 - val_loss: 440925344.0000 - val_mae: 440925344.0000\n",
      "Epoch 31/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 142.4813 - mae: 142.4813 - val_loss: 441132576.0000 - val_mae: 441132576.0000\n",
      "Epoch 32/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 133.3461 - mae: 133.3461 - val_loss: 442738816.0000 - val_mae: 442738816.0000\n",
      "Epoch 33/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 127.4591 - mae: 127.4591 - val_loss: 445071808.0000 - val_mae: 445071808.0000\n",
      "Epoch 34/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 124.2516 - mae: 124.2516 - val_loss: 444543360.0000 - val_mae: 444543360.0000\n",
      "Epoch 35/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 126.3405 - mae: 126.3405 - val_loss: 446009152.0000 - val_mae: 446009152.0000\n",
      "Epoch 36/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 129.0038 - mae: 129.0038 - val_loss: 447039872.0000 - val_mae: 447039872.0000\n",
      "Epoch 37/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 125.1426 - mae: 125.1426 - val_loss: 445514624.0000 - val_mae: 445514624.0000\n",
      "Epoch 38/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 127.8075 - mae: 127.8075 - val_loss: 445076384.0000 - val_mae: 445076384.0000\n",
      "Epoch 39/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 122.3944 - mae: 122.3944 - val_loss: 443969632.0000 - val_mae: 443969632.0000\n",
      "Epoch 40/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 123.1499 - mae: 123.1499 - val_loss: 442579872.0000 - val_mae: 442579872.0000\n",
      "Epoch 41/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 127.2924 - mae: 127.2924 - val_loss: 440868000.0000 - val_mae: 440868000.0000\n",
      "Epoch 42/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 126.1934 - mae: 126.1934 - val_loss: 438439680.0000 - val_mae: 438439680.0000\n",
      "Epoch 43/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 115.3544 - mae: 115.3544 - val_loss: 438823296.0000 - val_mae: 438823296.0000\n",
      "Epoch 44/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 121.5976 - mae: 121.5976 - val_loss: 438384096.0000 - val_mae: 438384096.0000\n",
      "Epoch 45/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 125.2097 - mae: 125.2097 - val_loss: 435527360.0000 - val_mae: 435527360.0000\n",
      "Epoch 46/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 116.0877 - mae: 116.0877 - val_loss: 434577440.0000 - val_mae: 434577440.0000\n",
      "Epoch 47/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 100.2295 - mae: 100.2295 - val_loss: 434588800.0000 - val_mae: 434588800.0000\n",
      "Epoch 48/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 118.5828 - mae: 118.5828 - val_loss: 431077536.0000 - val_mae: 431077536.0000\n",
      "Epoch 49/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 113.8643 - mae: 113.8643 - val_loss: 428909280.0000 - val_mae: 428909280.0000\n",
      "Epoch 50/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 114.9156 - mae: 114.9156 - val_loss: 428884800.0000 - val_mae: 428884800.0000\n",
      "Epoch 51/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 114.8566 - mae: 114.8566 - val_loss: 426948224.0000 - val_mae: 426948224.0000\n",
      "Epoch 52/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 109.3446 - mae: 109.3446 - val_loss: 426574592.0000 - val_mae: 426574592.0000\n",
      "Epoch 53/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 117.5978 - mae: 117.5978 - val_loss: 424025664.0000 - val_mae: 424025664.0000\n",
      "Epoch 54/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 105.3196 - mae: 105.3196 - val_loss: 423959584.0000 - val_mae: 423959584.0000\n",
      "Epoch 55/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 114.9202 - mae: 114.9202 - val_loss: 421100000.0000 - val_mae: 421100000.0000\n",
      "Epoch 56/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 115.1983 - mae: 115.1983 - val_loss: 420380096.0000 - val_mae: 420380096.0000\n",
      "Epoch 57/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 101.2721 - mae: 101.2721 - val_loss: 418669888.0000 - val_mae: 418669888.0000\n",
      "Epoch 58/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 108.4618 - mae: 108.4618 - val_loss: 417876672.0000 - val_mae: 417876672.0000\n",
      "Epoch 59/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 124.7863 - mae: 124.7863 - val_loss: 415695872.0000 - val_mae: 415695872.0000\n",
      "Epoch 60/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 116.5144 - mae: 116.5144 - val_loss: 414087072.0000 - val_mae: 414087072.0000\n",
      "Epoch 61/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 106.3182 - mae: 106.3182 - val_loss: 414382720.0000 - val_mae: 414382720.0000\n",
      "Epoch 62/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 129.3980 - mae: 129.3980 - val_loss: 411915808.0000 - val_mae: 411915808.0000\n",
      "Epoch 63/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 109.4845 - mae: 109.4845 - val_loss: 411062368.0000 - val_mae: 411062368.0000\n",
      "Epoch 64/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 111.4376 - mae: 111.4376 - val_loss: 410750368.0000 - val_mae: 410750368.0000\n",
      "Epoch 65/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 101.5777 - mae: 101.5777 - val_loss: 408774944.0000 - val_mae: 408774944.0000\n",
      "Epoch 66/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 95.7625 - mae: 95.7625 - val_loss: 406581952.0000 - val_mae: 406581952.0000\n",
      "Epoch 67/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 104.9849 - mae: 104.9849 - val_loss: 406251360.0000 - val_mae: 406251360.0000\n",
      "Epoch 68/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 105.6650 - mae: 105.6650 - val_loss: 405608928.0000 - val_mae: 405608928.0000\n",
      "Epoch 69/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 112.1718 - mae: 112.1718 - val_loss: 403682016.0000 - val_mae: 403682016.0000\n",
      "Epoch 70/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 92.6190 - mae: 92.6190 - val_loss: 401933952.0000 - val_mae: 401933952.0000\n",
      "Epoch 71/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 106.1917 - mae: 106.1917 - val_loss: 400728992.0000 - val_mae: 400728992.0000\n",
      "Epoch 72/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 106.0659 - mae: 106.0659 - val_loss: 399220096.0000 - val_mae: 399220096.0000\n",
      "Epoch 73/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 98.2277 - mae: 98.2277 - val_loss: 397131296.0000 - val_mae: 397131296.0000\n",
      "Epoch 74/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 104.9837 - mae: 104.9837 - val_loss: 395632960.0000 - val_mae: 395632960.0000\n",
      "Epoch 75/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 101.3483 - mae: 101.3483 - val_loss: 395751456.0000 - val_mae: 395751456.0000\n",
      "Epoch 76/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 99.0693 - mae: 99.0693 - val_loss: 393543392.0000 - val_mae: 393543392.0000\n",
      "Epoch 77/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 108.9019 - mae: 108.9019 - val_loss: 391117440.0000 - val_mae: 391117440.0000\n",
      "Epoch 78/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 102.9903 - mae: 102.9903 - val_loss: 389822784.0000 - val_mae: 389822784.0000\n",
      "Epoch 79/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 96.6627 - mae: 96.6627 - val_loss: 389664032.0000 - val_mae: 389664032.0000\n",
      "Epoch 80/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 101.2787 - mae: 101.2787 - val_loss: 388558752.0000 - val_mae: 388558752.0000\n",
      "Epoch 81/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 93.4090 - mae: 93.4090 - val_loss: 385855872.0000 - val_mae: 385855872.0000\n",
      "Epoch 82/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 97.1590 - mae: 97.1590 - val_loss: 384985408.0000 - val_mae: 384985408.0000\n",
      "Epoch 83/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 89.7840 - mae: 89.7840 - val_loss: 383256576.0000 - val_mae: 383256576.0000\n",
      "Epoch 84/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 91.1104 - mae: 91.1104 - val_loss: 381987456.0000 - val_mae: 381987456.0000\n",
      "Epoch 85/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 97.6158 - mae: 97.6158 - val_loss: 381720832.0000 - val_mae: 381720832.0000\n",
      "Epoch 86/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 84.3933 - mae: 84.3933 - val_loss: 378493120.0000 - val_mae: 378493120.0000\n",
      "Epoch 87/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 98.6270 - mae: 98.6270 - val_loss: 377927680.0000 - val_mae: 377927680.0000\n",
      "Epoch 88/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 96.5541 - mae: 96.5541 - val_loss: 377001152.0000 - val_mae: 377001152.0000\n",
      "Epoch 89/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 95.7892 - mae: 95.7892 - val_loss: 375644896.0000 - val_mae: 375644896.0000\n",
      "Epoch 90/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 103.8982 - mae: 103.8982 - val_loss: 373230112.0000 - val_mae: 373230112.0000\n",
      "Epoch 91/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 107.3369 - mae: 107.3369 - val_loss: 372900096.0000 - val_mae: 372900096.0000\n",
      "Epoch 92/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 86.8706 - mae: 86.8706 - val_loss: 369863584.0000 - val_mae: 369863584.0000\n",
      "Epoch 93/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 92.5005 - mae: 92.5005 - val_loss: 369473664.0000 - val_mae: 369473664.0000\n",
      "Epoch 94/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 94.8551 - mae: 94.8551 - val_loss: 368429632.0000 - val_mae: 368429632.0000\n",
      "Epoch 95/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 85.4472 - mae: 85.4472 - val_loss: 367472320.0000 - val_mae: 367472320.0000\n",
      "Epoch 96/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 107.8857 - mae: 107.8857 - val_loss: 366010912.0000 - val_mae: 366010912.0000\n",
      "Epoch 97/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 89.9645 - mae: 89.9645 - val_loss: 364948096.0000 - val_mae: 364948096.0000\n",
      "Epoch 98/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 93.7804 - mae: 93.7804 - val_loss: 363948416.0000 - val_mae: 363948416.0000\n",
      "Epoch 99/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 86.9373 - mae: 86.9373 - val_loss: 361755648.0000 - val_mae: 361755648.0000\n",
      "Epoch 100/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 94.5138 - mae: 94.5138 - val_loss: 361122272.0000 - val_mae: 361122272.0000\n",
      "Epoch 101/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 101.9860 - mae: 101.9860 - val_loss: 359840448.0000 - val_mae: 359840448.0000\n",
      "Epoch 102/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 99.4363 - mae: 99.4363 - val_loss: 358987360.0000 - val_mae: 358987360.0000\n",
      "Epoch 103/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 78.2713 - mae: 78.2713 - val_loss: 358516864.0000 - val_mae: 358516864.0000\n",
      "Epoch 104/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 85.7327 - mae: 85.7327 - val_loss: 358757056.0000 - val_mae: 358757056.0000\n",
      "Epoch 105/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 83.6675 - mae: 83.6675 - val_loss: 356234400.0000 - val_mae: 356234400.0000\n",
      "Epoch 106/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 88.3598 - mae: 88.3598 - val_loss: 356028416.0000 - val_mae: 356028416.0000\n",
      "Epoch 107/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 86.7390 - mae: 86.7390 - val_loss: 351923200.0000 - val_mae: 351923200.0000\n",
      "Epoch 108/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 101.3816 - mae: 101.3816 - val_loss: 351730208.0000 - val_mae: 351730208.0000\n",
      "Epoch 109/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 92.1465 - mae: 92.1465 - val_loss: 351553568.0000 - val_mae: 351553568.0000\n",
      "Epoch 110/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 82.3027 - mae: 82.3027 - val_loss: 351120352.0000 - val_mae: 351120352.0000\n",
      "Epoch 111/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 81.9534 - mae: 81.9534 - val_loss: 350301152.0000 - val_mae: 350301152.0000\n",
      "Epoch 112/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 81.9514 - mae: 81.9514 - val_loss: 348956384.0000 - val_mae: 348956384.0000\n",
      "Epoch 113/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 85.8268 - mae: 85.8268 - val_loss: 348085568.0000 - val_mae: 348085568.0000\n",
      "Epoch 114/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 86.0703 - mae: 86.0703 - val_loss: 349449600.0000 - val_mae: 349449600.0000\n",
      "Epoch 115/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 87.4435 - mae: 87.4435 - val_loss: 346944480.0000 - val_mae: 346944480.0000\n",
      "Epoch 116/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 90.5621 - mae: 90.5621 - val_loss: 345209728.0000 - val_mae: 345209728.0000\n",
      "Epoch 117/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 91.0517 - mae: 91.0517 - val_loss: 343946496.0000 - val_mae: 343946496.0000\n",
      "Epoch 118/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 84.5904 - mae: 84.5904 - val_loss: 341745120.0000 - val_mae: 341745120.0000\n",
      "Epoch 119/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 92.1360 - mae: 92.1360 - val_loss: 341309408.0000 - val_mae: 341309408.0000\n",
      "Epoch 120/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 77.4152 - mae: 77.4152 - val_loss: 340819648.0000 - val_mae: 340819648.0000\n",
      "Epoch 121/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 96.2441 - mae: 96.2441 - val_loss: 339186016.0000 - val_mae: 339186016.0000\n",
      "Epoch 122/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 87.4249 - mae: 87.4249 - val_loss: 337813536.0000 - val_mae: 337813536.0000\n",
      "Epoch 123/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 96.8623 - mae: 96.8623 - val_loss: 336503488.0000 - val_mae: 336503488.0000\n",
      "Epoch 124/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 85.9180 - mae: 85.9180 - val_loss: 337815808.0000 - val_mae: 337815808.0000\n",
      "Epoch 125/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 88.2391 - mae: 88.2391 - val_loss: 335026848.0000 - val_mae: 335026848.0000\n",
      "Epoch 126/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 95.0096 - mae: 95.0096 - val_loss: 333227648.0000 - val_mae: 333227648.0000\n",
      "Epoch 127/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 101.2006 - mae: 101.2006 - val_loss: 331064864.0000 - val_mae: 331064864.0000\n",
      "Epoch 128/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 73.5475 - mae: 73.5475 - val_loss: 331711904.0000 - val_mae: 331711904.0000\n",
      "Epoch 129/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 91.9096 - mae: 91.9096 - val_loss: 328925792.0000 - val_mae: 328925792.0000\n",
      "Epoch 130/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 93.4805 - mae: 93.4805 - val_loss: 329269472.0000 - val_mae: 329269472.0000\n",
      "Epoch 131/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 86.5398 - mae: 86.5398 - val_loss: 328990912.0000 - val_mae: 328990912.0000\n",
      "Epoch 132/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 76.4759 - mae: 76.4759 - val_loss: 327185408.0000 - val_mae: 327185408.0000\n",
      "Epoch 133/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 78.9281 - mae: 78.9281 - val_loss: 325862880.0000 - val_mae: 325862880.0000\n",
      "Epoch 134/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 83.0811 - mae: 83.0811 - val_loss: 324527296.0000 - val_mae: 324527296.0000\n",
      "Epoch 135/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 87.7348 - mae: 87.7348 - val_loss: 323366880.0000 - val_mae: 323366880.0000\n",
      "Epoch 136/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 83.0227 - mae: 83.0227 - val_loss: 322512224.0000 - val_mae: 322512224.0000\n",
      "Epoch 137/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 76.5536 - mae: 76.5536 - val_loss: 322595808.0000 - val_mae: 322595808.0000\n",
      "Epoch 138/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 84.6950 - mae: 84.6950 - val_loss: 320686784.0000 - val_mae: 320686784.0000\n",
      "Epoch 139/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 98.7424 - mae: 98.7424 - val_loss: 320318784.0000 - val_mae: 320318784.0000\n",
      "Epoch 140/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 76.1825 - mae: 76.1825 - val_loss: 319209952.0000 - val_mae: 319209952.0000\n",
      "Epoch 141/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 74.2500 - mae: 74.2500 - val_loss: 317695424.0000 - val_mae: 317695424.0000\n",
      "Epoch 142/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 83.4300 - mae: 83.4300 - val_loss: 315403232.0000 - val_mae: 315403232.0000\n",
      "Epoch 143/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 85.0389 - mae: 85.0389 - val_loss: 314930528.0000 - val_mae: 314930528.0000\n",
      "Epoch 144/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 81.4101 - mae: 81.4101 - val_loss: 313827744.0000 - val_mae: 313827744.0000\n",
      "Epoch 145/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 84.2014 - mae: 84.2014 - val_loss: 314319232.0000 - val_mae: 314319232.0000\n",
      "Epoch 146/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 70.1677 - mae: 70.1677 - val_loss: 312186752.0000 - val_mae: 312186752.0000\n",
      "Epoch 147/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 77.0756 - mae: 77.0756 - val_loss: 311133824.0000 - val_mae: 311133824.0000\n",
      "Epoch 148/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 77.2253 - mae: 77.2253 - val_loss: 311394784.0000 - val_mae: 311394784.0000\n",
      "Epoch 149/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 87.3097 - mae: 87.3097 - val_loss: 308618176.0000 - val_mae: 308618176.0000\n",
      "Epoch 150/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 79.3015 - mae: 79.3015 - val_loss: 306836064.0000 - val_mae: 306836064.0000\n",
      "Epoch 151/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 79.4665 - mae: 79.4665 - val_loss: 306243520.0000 - val_mae: 306243520.0000\n",
      "Epoch 152/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 84.9057 - mae: 84.9057 - val_loss: 305528448.0000 - val_mae: 305528448.0000\n",
      "Epoch 153/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 82.6324 - mae: 82.6324 - val_loss: 304528704.0000 - val_mae: 304528704.0000\n",
      "Epoch 154/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 82.2642 - mae: 82.2642 - val_loss: 303143616.0000 - val_mae: 303143616.0000\n",
      "Epoch 155/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 85.2337 - mae: 85.2337 - val_loss: 302189856.0000 - val_mae: 302189856.0000\n",
      "Epoch 156/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 77.8764 - mae: 77.8764 - val_loss: 300271616.0000 - val_mae: 300271616.0000\n",
      "Epoch 157/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 92.0166 - mae: 92.0166 - val_loss: 300576992.0000 - val_mae: 300576992.0000\n",
      "Epoch 158/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 81.7133 - mae: 81.7133 - val_loss: 300874624.0000 - val_mae: 300874624.0000\n",
      "Epoch 159/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 76.6389 - mae: 76.6389 - val_loss: 299787520.0000 - val_mae: 299787520.0000\n",
      "Epoch 160/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 88.2128 - mae: 88.2128 - val_loss: 298342944.0000 - val_mae: 298342944.0000\n",
      "Epoch 161/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 76.5937 - mae: 76.5937 - val_loss: 298243200.0000 - val_mae: 298243200.0000\n",
      "Epoch 162/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 80.1968 - mae: 80.1968 - val_loss: 296572736.0000 - val_mae: 296572736.0000\n",
      "Epoch 163/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 79.5546 - mae: 79.5546 - val_loss: 296739776.0000 - val_mae: 296739776.0000\n",
      "Epoch 164/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 79.6607 - mae: 79.6607 - val_loss: 296953600.0000 - val_mae: 296953600.0000\n",
      "Epoch 165/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 84.0023 - mae: 84.0023 - val_loss: 296083360.0000 - val_mae: 296083360.0000\n",
      "Epoch 166/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 83.5069 - mae: 83.5069 - val_loss: 295760672.0000 - val_mae: 295760672.0000\n",
      "Epoch 167/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 69.6682 - mae: 69.6682 - val_loss: 297041824.0000 - val_mae: 297041824.0000\n",
      "Epoch 168/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 68.4531 - mae: 68.4531 - val_loss: 295349152.0000 - val_mae: 295349152.0000\n",
      "Epoch 169/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 81.2756 - mae: 81.2756 - val_loss: 294007648.0000 - val_mae: 294007648.0000\n",
      "Epoch 170/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 78.2807 - mae: 78.2807 - val_loss: 293623904.0000 - val_mae: 293623904.0000\n",
      "Epoch 171/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 81.8311 - mae: 81.8311 - val_loss: 291894912.0000 - val_mae: 291894912.0000\n",
      "Epoch 172/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 80.5174 - mae: 80.5174 - val_loss: 289941344.0000 - val_mae: 289941344.0000\n",
      "Epoch 173/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 76.4102 - mae: 76.4102 - val_loss: 290266592.0000 - val_mae: 290266592.0000\n",
      "Epoch 174/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 77.3749 - mae: 77.3749 - val_loss: 290977792.0000 - val_mae: 290977792.0000\n",
      "Epoch 175/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 75.1911 - mae: 75.1911 - val_loss: 289202080.0000 - val_mae: 289202080.0000\n",
      "Epoch 176/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 81.2020 - mae: 81.2020 - val_loss: 289278336.0000 - val_mae: 289278336.0000\n",
      "Epoch 177/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 89.7613 - mae: 89.7613 - val_loss: 288287328.0000 - val_mae: 288287328.0000\n",
      "Epoch 178/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 73.7834 - mae: 73.7834 - val_loss: 288466592.0000 - val_mae: 288466592.0000\n",
      "Epoch 179/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 82.2722 - mae: 82.2722 - val_loss: 288406208.0000 - val_mae: 288406208.0000\n",
      "Epoch 180/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 74.8875 - mae: 74.8875 - val_loss: 287075872.0000 - val_mae: 287075872.0000\n",
      "Epoch 181/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 81.2613 - mae: 81.2613 - val_loss: 285990176.0000 - val_mae: 285990176.0000\n",
      "Epoch 182/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 79.0089 - mae: 79.0089 - val_loss: 286346496.0000 - val_mae: 286346496.0000\n",
      "Epoch 183/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 80.1334 - mae: 80.1334 - val_loss: 283786784.0000 - val_mae: 283786784.0000\n",
      "Epoch 184/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 80.6605 - mae: 80.6605 - val_loss: 285600544.0000 - val_mae: 285600544.0000\n",
      "Epoch 185/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 83.2148 - mae: 83.2148 - val_loss: 283203264.0000 - val_mae: 283203264.0000\n",
      "Epoch 186/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 78.9556 - mae: 78.9556 - val_loss: 284312096.0000 - val_mae: 284312096.0000\n",
      "Epoch 187/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 79.3382 - mae: 79.3382 - val_loss: 282962560.0000 - val_mae: 282962560.0000\n",
      "Epoch 188/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 78.7505 - mae: 78.7505 - val_loss: 282465760.0000 - val_mae: 282465760.0000\n",
      "Epoch 189/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 79.8584 - mae: 79.8584 - val_loss: 281657152.0000 - val_mae: 281657152.0000\n",
      "Epoch 190/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 77.5090 - mae: 77.5090 - val_loss: 281829568.0000 - val_mae: 281829568.0000\n",
      "Epoch 191/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 75.6436 - mae: 75.6436 - val_loss: 281233888.0000 - val_mae: 281233888.0000\n",
      "Epoch 192/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 89.1305 - mae: 89.1305 - val_loss: 280839040.0000 - val_mae: 280839040.0000\n",
      "Epoch 193/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 75.8891 - mae: 75.8891 - val_loss: 279509216.0000 - val_mae: 279509216.0000\n",
      "Epoch 194/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 86.4700 - mae: 86.4700 - val_loss: 280647808.0000 - val_mae: 280647808.0000\n",
      "Epoch 195/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 82.0176 - mae: 82.0176 - val_loss: 278282720.0000 - val_mae: 278282720.0000\n",
      "Epoch 196/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 75.3183 - mae: 75.3183 - val_loss: 277506528.0000 - val_mae: 277506528.0000\n",
      "Epoch 197/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 74.7140 - mae: 74.7140 - val_loss: 277708416.0000 - val_mae: 277708416.0000\n",
      "Epoch 198/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 85.0417 - mae: 85.0417 - val_loss: 277737920.0000 - val_mae: 277737920.0000\n",
      "Epoch 199/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 66.9553 - mae: 66.9553 - val_loss: 278883456.0000 - val_mae: 278883456.0000\n",
      "Epoch 200/200\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 90.6064 - mae: 90.6064 - val_loss: 279014656.0000 - val_mae: 279014656.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2b98cba4090>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SANN_model.fit(\n",
    "    scaled_training_features,\n",
    "    training_target,\n",
    "    epochs=200,\n",
    "    batch_size=10,\n",
    "    validation_data=(testing_features, testing_target)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
